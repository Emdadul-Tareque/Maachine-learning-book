{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# অধ্যায় ৭ঃ রিসমেপ্লিয়ের মাধ্যমে মেশিন লার্নিং এলগরিদম এভ্যালুয়েট করা  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "আমাদের মেশিন লার্নিং মডেলটি না দেখা ডেটার উপর কেমন কাজ করছে তা জানা দরকার। তা না হলে মডেল কেমন কাজ করছে জানব কিভাবে। তার জন্য একটা ভাল উপায় হচ্ছে আমাদের লেভেল ডেটাসেটটিকে দুইভাগে ভাগ করে যেতে পারে । যেহেতু আমাদের ডেটাসেটিটিতে প্রশ্নের সাথে উত্তর দেওয়া আছে সেক্ষেত্রে আমরা ট্রেনিং ডেটা দিয়ে ট্রেইন করিয়ে টেস্ট ডেটা দিয়ে পরীক্ষা করতে পারি। \n",
    "আরেকটি ভালো উপায় হচ্ছে স্ট্যাটিস্টিক এর রিসেমপ্লিং ম্যাথড ব্যবহার করে মডেল নতুন ডেটার উপর কেমন কাজ করছে না জানা। \n",
    "এই অধ্যায়ে আমরা স্ট্যাটিস্টিক এর রিসেমপ্লিং ম্যাথড ব্যবহার করে মডেল নতুন ডেটার উপর কেমন কাজ করছে তা শিখব । \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ৭.১ এভ্যালুয়েট মেশিন লার্নিং এলগরিদম \n",
    "আমাদের মনে হতে পারে আমরা কেনও পুরো ডেটা দিয়ে মডেলকে ট্রেনিং করাই না । এর কারণ হচ্ছে মডেল ওভারফিটিং হয়ে যায় অর্থাৎ মডেল ট্রেনিং ডেটার উপর ভালো পারফর্মেনস করে  করে কিন্তু টেস্ট ডেটার অর্থাৎ না দেখা ডেটার উপর পারফর্মেন্স খারাপ করে। \n",
    "\n",
    "মনে করুন আপনি একটি ডেটসেট  মেশিন লার্নিং মডেল তৈরি করলেন এবং সেই ডেটাসেট দিয়েই মেশিন কে টেস্ট করলেন । দেখলেন মডেলের এক্যুরিসে অনেক ভালো প্রায় ১০০% এর কাছাকাছি কিন্তু মডেলটিকে না  দেখা ডেটা দিয়ে টেস্ট করিয়ে দেখলেন মডেলের এক্যুরেসি নেমে ৭০% হয়ে গেছে । অর্থাৎ আপনার মডেলটি ওভারফিটিং হয়ে গেছে। আপনি তো অবশ্যই চাইবেন না আপনার মডেল এমন কাজ করুক। এই জন্য ডেটাসেটিকে দুইভাগে ভাগ করে কাজ করতে হয় । \n",
    "আমরা এই অধ্যায়ে চার ধরনের রেসেমপ্লিং টেকনিক নিয়ে আলোচনা করব -- \n",
    "\n",
    "১)  Train and Test Sets.\n",
    "\n",
    "২) k-fold Cross Validation.\n",
    "\n",
    "৩) Leave One Out Cross Validation.\n",
    "\n",
    "৪) Repeated Random Test-Train Splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ৭.২ ডেটাসেটকে দুইভাগে(Train and Test ) ভাগ করা "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "সম্পূর্ন ডেটাসেটকে দুইভাগে ভাগ করে । এক ভাগ দিয়ে ডেটাকে ট্রেইন করানো যাকে train dataset বলা হয় । আরেক ভাগ দিয়ে মডেল কেমন কাজ করছে তা পরীক্ষা করা যাকে বলা হয় test dataset। এই টেকনিকটি বড় ডেটাসেটের জন্য খুব ভালো কাজ করে। \n",
    "scikit-learn এ train_test_split ফাংশনের মাধ্যমে খুব সহজে ডেটাসেটকে ভাগ করা যায় "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 69.291%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate using a train and a test set\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#load dataset\n",
    "dataframe = pd.read_csv('diabetes.csv')\n",
    "array = dataframe.values\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\n",
    "random_state=seed)\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "result = model.score(X_test, Y_test)\n",
    "print(\"Accuracy: %.3f%%\" % (result*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ৭.৩ K-fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-fold cross validation টেকনিকে আমরা প্রথমে dataset কে k-সংখ্যক সমান ভাগে ভাগ করে ফেলি। ভাগটা হয় র‍্যান্ডমলি । এরপর এই  k-সংখ্যক ভাগ থেকে প্রতিবার (k-1) সংখ্যক ভাগ দিয়ে মেশিন লার্নিং এলগরিদম দিয়ে মডেলকে ট্রেইন করি বাকি ভাগ দিয়ে টেস্ট করা হয় । তাই যেটা হয় যে, আমাদের k-সংখ্যক ভাগের ভেতর প্রতিটা ভাগ একবার না একবার টেস্ট হিসেবে ব্যবহৃত হয় । প্রতিবার ভিন্ন ভিন্ন টেস্টের জন্য মডেলের এক্যুরেসি বের করে তাদের গড় মান বের করা হয় এতে করে মডেলের পারফর্মেনস কেমন তা জানা যায়। \n",
    "scikit-learn এ k-fold ক্লাস ব্যবহার করে এই কাজটি করা যায় "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 71.099% (5.079%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "num_folds = 10\n",
    "seed = 7\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "model = KNeighborsClassifier()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ৭.৪ Leave One Out Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-fold cross validation এ আমরা ডেটাসেটের কিছু ডেটাকে ট্রেনিং এবং কিছু ডেটাকে টেস্ট ডেটায় ভাগ করি k- সংখ্যক বার।\n",
    "Leave One Out Cross Validation এর ক্ষেত্রে সম্পূর্ন ডেটাসেটের মাত্র একটি ডেটাকে টেস্টের জন্য রেখে বাকি ডেটা দিয়ে ট্রেনিং করানো হয় যতক্ষণ না ডেটা সেটের প্রতিটা  ডেটা একবার করে টেস্ট ডেটা হিসেবে ব্যবহার হচ্ছে। উদাহরণ হয়ে বুঝা যাক \n",
    "মনে করি আমার কাছে ১০০টি ডেটার একটি ডেটা সেট আছে যা প্রথম ডেটাকে আমি টেস্টের জন্য রেখে বাকি  ৯৯ টি ডেটা দিয়ে আমি ডেটাকে ট্রেইন করাবো।  এরপর আবার আমি ২য় ডেটাকে টেস্টের জন্য রাখব বাকি ৯৯ ডেটাকে(১ম ডেটাটি সহ) দিয়ে ট্রেইন করাব।   এভাবে যতক্ষণ না প্রতিটা ডেটাকে টেস্ট ডেটা হিসবে ব্যবহার হচ্ছে ততক্ষণ এরূপ হতে থাকবে।  এইভাবে প্রতিবার পাওয়া এক্যুরেসিকে গড় করে মডেলের এক্যুরেসি হিসাব করা হয়। "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 71.484% (45.149%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "num_folds = 10\n",
    "loocv = LeaveOneOut()\n",
    "model = KNeighborsClassifier()\n",
    "results = cross_val_score(model, X, Y, cv=loocv)\n",
    "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ৭.৫ Repeated Random Test-Train Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 71.339% (2.321%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "n_splits = 10\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "kfold = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=seed)\n",
    "model = KNeighborsClassifier()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ৭.৬ কখন কোন টেকনিক ব্যবহার করব  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "১) k-fold ক্রস ভ্যালিডেশন মডেল এভ্যালুয়েশনের জন্য ভালো একটি টেকনিক । এটি প্রায়ই সময় ব্যবহার করা হয় । \n",
    "\n",
    "২) যখন অনেক ডেটা এবং স্লো এল্গরিদনম ব্যবহার করা হবে তখন train/test split টেকনিক ব্যবহার করা হয়। \n",
    "\n",
    "৩) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ৭.৭ এই অধ্যায়ে যা যা শিখেছি \n",
    "এই অধ্যাইয়ে আমরা মডেল এভ্যালুয়েশনের কিছু টেকনিক নিয়ে আলোচনা করেছি । সেগুলো হচ্ছে -- \n",
    "\n",
    "১) Train and Test Sets.\n",
    "\n",
    "২) k-fold Cross Validation.\n",
    "\n",
    "৩) Leave One Out Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ৭.৮ পরের অধ্যায় যা যা শিখব \n",
    "পরের অধ্যায়ে আমরা শিখব আমাদের মডেল কেমন পারফরমেন্স করছে সে সম্পর্কে জানার জন্য কিছু টেকনিক। ইনশাআল্লাহ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
